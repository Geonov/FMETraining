## Improving Reader Performance ##

The most important method to improve reading performance is to minimize the amount of data that is being read. As already mentioned, reading excess features counts as unnecessary work and is therefore inefficient.

---

### Filtering Input ###

For example, this workspace reads nearly 14,000 features, but immediately discards all except 419 of them (ones where the owner's name begins with "C":

![](./Images/Img2.014.ImprovingReaderPerformanceBadWorkspace.png)

In this scenario, if possible, it would be much more efficient to simply just read those approximately 400 features. All formats have various sets of parameters that speed up feature reading by filtering the amount of data being read. 

![](./Images/Img2.015.ImprovingReaderPerformanceNavParams.png)

The first of these – search envelope – defines the data to read as a geographic area. Then only that area of data needs to be read. These parameters are available on every spatial data reader, but have the most effect when the source data is spatially indexed. Then the query is being carried out at its most efficient.

Similarly, there are a number of parameters designed to let the user define how many features to read. These parameters include the ability to define a maximum number of features to read, and what feature to start at. There is also a parameter that defines which feature types (layers or tables) should be read.

By using these judiciously, the amount of data being read can be reduced and the translation sped up. For example, if we knew that the first records in the dataset were the ones beginning with "C", we could set Max Features to Read to 419. 

Other formats – particularly databases – have additional clauses that can help reduce the data flow:

![](./Images/Img2.016.ImprovingReaderPerformanceSQLWhere.png)

Here, for example, this Geodatabase reader has a ‘WHERE Clause’ parameter that applies the "owner name begins with 'C' test" in a way that is more efficient than reading the entire contents of a large table and using a Tester transformer.

![](./Images/Img2.017.ImprovingReaderPerformanceSQLWhereResults.png)

---

<table style="border-spacing: 0px">
<tr>
<td style="vertical-align:middle;background-color:darkorange;border: 2px solid darkorange">
<i class="fa fa-quote-left fa-lg fa-pull-left fa-fw" style="color:white;padding-right: 12px;vertical-align:text-top"></i>
<span style="color:white;font-size:x-large;font-weight: bold;font-family:serif">Jake Speedie says…</span>
</td>
</tr>

<tr>
<td style="border: 1px solid darkorange">
<span style="font-family:serif; font-style:italic; font-size:larger">
In short, when you want to filter source data, and can use a specific reader parameter to do so, it is more efficient than reading all of the source data and then filtering it with a transformer.
</span>
</td>
</tr>
</table>

---

### Excess Feature Types ###

Another potential bottleneck - specifically for formats with a table list – is the case where you have more feature types than are necessary.

Here the user has added a number of tables to their PostGIS database reader:

![](./Images/Img2.018.ReaderPerformanceFeatureTypeList.png)

However, if you look at the workspace, many of these tables are not even connected to anything. The unconnected tables are still being read but the data is being ignored:

![](./Images/Img2.019.ReaderPerformanceUnusedFeatureType.png)

Presumably the user added the tables for some reason, but then decided they did not need them, In that case they should delete the feature type from the FME workspace. Then the table will not be read and performance will improve.

---

### Dangling Readers ###

Another problem scenario - this time for file-based datasets - is a dangling reader. This is where a user deletes all of the feature types, but not the underlying reader:

![](./Images/Img2.020.ReaderPerformanceDanglingReader.png)

Here the user added a reader to read a MicroStation dataset. The feature type (layer) definitions were deleted from the workspace, but the reader remains.

In this case, when the workspace is run, all the data is still read from the file, but then immediately discarded as "Unexpected Input." 

The log reports:

<pre>
Unexpected Input Remover Nuker(TeeFactory): Cloned 1945 input feature(s) into 0 output feature(s)
</pre>

Remember, any extra data that is read – of whatever amount – takes time and resources to read, and impacts performance. In this case the user should have deleted the reader too.

---

<!--Tip Section--> 

<table style="border-spacing: 0px">
<tr>
<td style="vertical-align:middle;background-color:darkorange;border: 2px solid darkorange">
<i class="fa fa-info-circle fa-lg fa-pull-left fa-fw" style="color:white;padding-right: 12px;vertical-align:text-top"></i>
<span style="color:white;font-size:x-large;font-weight: bold;font-family:serif">TIP</span>
</td>
</tr>

<tr>
<td style="border: 1px solid darkorange">
<span style="font-family:serif; font-style:italic; font-size:larger">
One other obvious way to improve reading performance is to upgrade the underlying system to minimize the amount of time FME spends waiting for a response.
<br><br>For example, tune your database so that it responds to queries quicker, and use a solid-state hard drive so that file datasets can be read quicker.
</span>
</td>
</tr>
</table>
